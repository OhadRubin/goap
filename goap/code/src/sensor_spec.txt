SPECIFICATION FOR A GOAP SYSTEM WITH SENSORS AND WORKING MEMORY

INTRODUCTION  
This specification describes a specialized Goal-Oriented Action Planning (GOAP) system that incorporates sensors, working memory, and a state machine to distribute computation and drive AI behavior in real time. Implement the entire code architecture described here to replicate the system exactly.

CONTENTS  
1. Overview of the Agent Architecture  
2. Required Classes, Interfaces, and Data Structures  
3. Sensors and Workings of WorkingMemoryFacts  
4. Planner and Action Mechanics  
5. WorldState and Blackboard-like Integration  
6. State Machine (MethodicalMachine) and the Automaton  
7. Putting it All Together (AutomatonController)  
8. Example Shell Command Usage  
9. Example Main Function and Execution Flow  
10. Implementation Checklist  

────────────────────────────────────────────────────────────────────
1. OVERVIEW OF THE AGENT ARCHITECTURE
────────────────────────────────────────────────────────────────────

The agent architecture is similar to the MIT Media Lab’s C4 notion of using a blackboard, working memory, sensors, and multiple subsystems. In this system:

• Sensors detect changes in the environment (or internal states) and store perceptions in working memory.  
• The planner uses these perceptions to guide decision making, formulating a plan of actions to satisfy the current goal.  
• Actions, when executed, write instructions (e.g., new destinations) to a blackboard-like data storage (here represented by a WorldState plus the Automaton’s internal structures). Other subsystems (navigation, animation, combat, etc.) update accordingly.  

One of the key points is to distribute potentially costly computations over many sensor updates, caching partial results in working memory. The planner references these cached values when validating preconditions.

────────────────────────────────────────────────────────────────────
2. REQUIRED CLASSES, INTERFACES, AND DATA STRUCTURES
────────────────────────────────────────────────────────────────────

Your implementation must define exactly the following classes (with the described methods and constructor parameters), ensuring you replicate the functionality in full detail. The associated file-level imports, exception handling, and usage of Python standard library or side libraries (like networkx, methodicalmachine) should be included accordingly.

A) Exceptions  
Define these exceptions as is:

• OperationFailedError(reason: str)  
  Indicates a high-level failure in an operation.

• SensorError (base class for sensor-related issues). Under it:  
  – SensorMultipleTypeError  
  – SensorDoesNotExistError  
  – SensorAlreadyInCollectionError  

• PlanError (base class for planning issues). Under it:  
  – PlanFailed  

• ActionError (base class for action-related issues). Under it:  
  – ActionMultipleTypeError  
  – ActionAlreadyInCollectionError  

B) Action, ActionResponse, and Actions Collection

1) Action  
   class Action:  
       • constructor:  
         def __init__(self, func: Callable, name: str, conditions: dict, effects: dict, cost: float = 0.1)  
         – func: A callable containing the “execution logic” for the action.  
         – name: A unique string ID for the action.  
         – conditions: dict specifying symbolic conditions required to run (e.g., {"tmp_dir_state": "exist"}).  
         – effects: dict specifying which symbolic changes occur after completion.  
         – cost: numeric value representing cost in planning.  
       • exec(): runs self.func and returns an ActionResponse.  
       • response: property storing the last ActionResponse from exec().  

2) ActionResponse  
   class ActionResponse:  
       – holds stdout, stderr, return_code, plus a string property response returning stdout if available, else stderr.  

3) Actions (a collection of Action)  
   class Actions:  
       – holds a list of Action objects.  
       – add(name, conditions, effects, func, cost=0.1): adds a new Action. Raises ActionAlreadyInCollectionError if name duplicates.  
       – remove(name): removes an Action by name.  
       – get(name): returns the Action instance or None.  
       – run_all(): iterates all actions in the collection, calling exec.  

C) Graph Construction Data Structures (Node, Edge, Nodes, Edges, Graph)

1) Node(attributes: dict, weight: float=0.0)  
   – A node identified by a dict of attributes (the “symbolic world state” it represents).  

2) Edge(name, predecessor: Node, successor: Node, cost=0.0, obj: object=None)  
   – Connects two Nodes in a directed manner, labeled with “name,” holding a reference to an Action (obj).  

3) Nodes and Edges Collections  
   class Nodes: keeps a list of Node objects with helper methods (add, get, iteration).  
   class Edges: keeps a list of Edge objects with helper methods (add, iteration).  

4) Graph  
   – Must be built on networkx.DiGraph.  
   – add_nodes_from(nodes: Nodes) and add_edges_from(edges: Edges).  
   – path(src: Node, dst: Node): uses networkx’s astar_path to find a path.  
   – edge_between_nodes(path, data=True): returns the edges for a path.  

D) Planner  
   class Planner:  
       – constructor: Planner(actions: Actions)  
       – plan(state: dict, goal: dict) -> list of edges  
         1) Generate states from actions, the initial “world_state,” and the “goal.”  
         2) Generate transitions where each action’s conditions match a Node’s attributes.  
         3) Build a Graph and search from the initial Node to the goal Node with astar_path.  
         4) Return the path as a list of edges (the plan).  

E) Sensor, SensorResponse, and Sensors Collection

1) Sensor  
   class Sensor:  
       – constructor: Sensor(name: str, binding: str, func: Callable)  
         * name: unique ID  
         * binding: string key referencing where the sensor’s data is stored in working memory or the world state  
         * func: the callable that does the detection or computation  
       – exec(): calls func() and returns a SensorResponse  
       – The sensor sets self.response to the SensorResponse.  

2) SensorResponse  
   class SensorResponse:  
       – holds stdout, stderr, return_code, plus a property response that returns stdout if present, otherwise stderr.  

3) Sensors (a collection of Sensor)  
   class Sensors:  
       – add(name, binding, func): add a new unique sensor.  
       – remove(name)  
       – run_all(): calls exec on each sensor.  

F) WorldState  
   class WorldState(dict):  
       – A specialized dictionary with attribute-style access (ws.attr -> ws["attr"]).  
       – Must override __setitem__, __delitem__, __eq__, etc.  
       – The code holds usage akin to a blackboard or set of “symbols.”  

G) Fact  
   class Fact:  
       – constructor: Fact(sensor, data, binding) - holds a reference to the sensor name, the data, and the binding.  
       – each Fact is appended to the Automaton’s working_memory list.  

────────────────────────────────────────────────────────────────────
3. SENSORS AND WORKING MEMORYFACTS
────────────────────────────────────────────────────────────────────

Sensors are computational units that perceive or compute data. They store results in Fact objects, which are appended to the Automaton’s working_memory. The Fact object is minimal containing:

    Fact(sensor: str, data: SensorResponse, binding: str)
      – sensor: which sensor produced it
      – data: the SensorResponse
      – binding: the key used to write into the WorldState

After each sensor update, the Automaton writes Fact.data.response into the corresponding key in WorldState. By distributing heavy computations across sensors (e.g., pathfinding or line-of-sight tests), the code ensures the planner’s overhead is minimized at plan time.

────────────────────────────────────────────────────────────────────
4. PLANNER AND ACTION MECHANICS
────────────────────────────────────────────────────────────────────

The Planner implements a regressive search approach using a custom Graph:

• __generate_states: For each Action, create a Node for the pre-state based on (world_state + action.conditions) and a Node for the post-state based on (pre-state + action.effects).  
• __generate_transitions: For each Node that satisfies Action’s conditions, create an Edge to a Node that includes the Action’s effects.  
• plan(state, goal) => a list of edges:  
  – Build the states, transitions, construct a Graph.  
  – Use networkx.astar_path(...) to find a path from the Node matching “state” to the Node matching “goal.”  
  – Return the edges along that path.  

Each Action has conditions and effects, plus a cost. The search cost is the sum of Edge costs when building a solution path.

────────────────────────────────────────────────────────────────────
5. WORLDSTATE AND BLACKBOARD-LIKE INTEGRATION
────────────────────────────────────────────────────────────────────

The WorldState class acts as the blackboard storing the symbolic representation of the environment. The Automaton references it for the current state; sensors and actions update or read from it.  
• Accessing world_state.tmp_dir_state is syntactic sugar for world_state["tmp_dir_state"].  

Working memory is stored as a list of Fact objects in the Automaton. Once the Automaton calls sensors, each sensor result is turned into a Fact and appended to working_memory. The binding determines which key in world_state to set with fact.data.response.

────────────────────────────────────────────────────────────────────
6. STATE MACHINE (METHODICALMACHINE) AND THE AUTOMATON
────────────────────────────────────────────────────────────────────

A) The Automaton:  
   class Automaton:  
     – Has the following states using MethodicalMachine:  
       1) waiting_orders (initial)  
       2) sensing  
       3) planning  
       4) acting  
     – Input transitions (wait, sense, plan, act, input_goal).  
     – Output methods that do the actual sensor reading, plan building, and plan execution.  
     – Internal references:  
       • world_state (a WorldState)  
       • working_memory (list of Fact)  
       • sensors (Sensors)  
       • actions (Actions)  
       • planner (Planner)  
       • action_plan (list)  
       • goal (dict)  
       • actions_response (list of ActionResponse)  

B) State Machine Transitions:  
   1) waiting_orders → sense -> sensing  
      – calls __sense: runs sensors, appends Facts to working_memory, writes results to world_state.  
   2) sensing → plan -> planning  
      – calls __plan: uses self.planner.plan(...) to create edges representing a plan.  
   3) planning → act -> acting  
      – calls __act: iterates the plan edges, calling Action.exec on each.  
   4) acting → sense -> sensing  
      – calls __reset_working_memory and then __sense again.  
   5) waiting_orders, planning, and acting all also have input_goal, returning to waiting_orders after setting a new goal.  
   6) sensing can also go back to waiting_orders by the input “wait,” which resets working_memory.  

────────────────────────────────────────────────────────────────────
7. PUTTING IT ALL TOGETHER (AUTOMATONCONTROLLER)
────────────────────────────────────────────────────────────────────

class AutomatonController:  
• Holds an Automaton instance.  
• Provides high-level control with start(), which loops:  
  1) automaton.sense()  
  2) if world_state != goal:  
       – automaton.plan()  
       – automaton.act()  
     else:  
       – automaton.wait()  
  3) sleep(5)  

────────────────────────────────────────────────────────────────────
8. EXAMPLE SHELL COMMAND USAGE
────────────────────────────────────────────────────────────────────

ShellCommand is a helper:

class ShellCommand:  
  – constructor: ShellCommand(command: str, timeout: int=30)  
  – callable: run this shell command, capturing stdout, stderr, and return_code.

In the example:  
• "mkdir -p /tmp/goap_tmp" (to create a directory)  
• "touch /tmp/goap_tmp/.token" (to place a file)  
• Some read commands to check if directory exists or if a file is present.  

These shell commands are used by sensors (to sense "tmp_dir_state" or "tmp_dir_content") and by actions (to create the directory or token).

────────────────────────────────────────────────────────────────────
9. EXAMPLE MAIN FUNCTION AND EXECUTION FLOW
────────────────────────────────────────────────────────────────────

The example main() performs:

def main():  
  goal = {"tmp_dir_state": "exist", "tmp_dir_content": "token_found"}  
  dir_handler = setup_automaton()  
  dir_handler.goal = goal  
  dir_handler.start()

Where setup_automaton() builds an AutomatonController with initial world_state, sets up two sensors (SenseTmpDirState, SenseTmpDirContent) and two actions (CreateTmpDir, CreateToken).

Runtime Flow:  
1) The controller starts in an infinite loop.  
2) The Automaton’s “sense” transition is called. Both sensors run shell commands to see if /tmp/goap_tmp exists and if .token is there. The results are appended as Facts to working_memory, then written to the Automaton’s WorldState.  
3) If the current state does not match the goal, the controller triggers “plan.” The planner constructs a path from current state to goal by chaining the needed actions.  
4) Then “act” executes those actions in order (CreateTmpDir → CreateToken).  
5) After acting, the system goes back to sensing again. Next iteration, once the system sees that “tmp_dir_state=exist” and “tmp_dir_content=token_found,” it matches the goal, so the controller calls “wait” and repeats.

────────────────────────────────────────────────────────────────────
10. IMPLEMENTATION CHECKLIST
────────────────────────────────────────────────────────────────────

A) Classes & Methods
   □ Implement each exception class verbatim.  
   □ Ensure Action, ActionResponse, Actions mimic the outlines, hooking up the “exec()” method properly and storing responses.  
   □ Make Node, Edge, Nodes, Edges with the indicated fields.  
   □ Implement Graph with networkx, adding nodes and edges, providing path(...) with astar_path.  
   □ Create Planner, generating states and transitions, returning a list of edges.  
   □ Implement Sensor, SensorResponse, and Sensors exactly with add, remove, run_all, etc.  
   □ Provide a working memory of Fact objects in Automaton, storing sensor results.  
   □ Implement the Automaton with the 4 states (waiting_orders, sensing, planning, acting) and transitions.  
   □ The AutomatonController start() loop must compare WorldState and goal, calling sense → plan → act as needed.  

B) Verified Behavior  
   • The system must observe the environment (via sensors), build or rebuild plans on changes, and execute them by calling Action func callables.  
   • The ShellCommand usage is optional but recommended to replicate the example. Another user-supplied function is permissible as long as it returns (stdout, stderr, code).  
   • The system must update world_state after each sensor reading and run the plan until the goal is met.  

Following this specification ensures you can implement the described GOAP system, complete with sensors, working memory, and an automaton driving the sense-plan-act cycle. All the provided details, class structures, and method signatures are mandatory to replicate the exact functionality.