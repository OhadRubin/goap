You will be a file that implements a GOAP system.
It is a specialized version of GOAP that allows sensors and working memory to be used by the planner.
Your goal is to convert the code into a specification that would prompt someone to implement the *exact* system.
It is part of a homework assignment for students in a game programming course.

The quality of your specification will be evaluated by how well it can be used to implement the *exact* system, meaning that if you omit any details, the implementation will not be able to replicate the original system.



```
"""
## Agent Architecture

Our agent architecture resembles the MIT Media Lab's C4 (Burke et al. 2001). An agent is composed of a blackboard, working memory, a handful of subsystems, and some number of sensors. Sensors detect changes in the world, and deposit these perceptions in dynamic working memory. The planner uses these perceptions to guide its decision-making, and ultimately communicates instructions to subsystems through the blackboard. Subsystems include the targeting, navigation, animation, and weapons systems.

Sensors perceive external visible and audible stimuli, as well as internal stimuli such as pain and desires. Some sensors are event-driven while others poll. Event-driven sensors are useful for recognizing instantaneous events like sounds and damage. Polling works better for sensors that need to extract information from the world. For example, a sensor may generate a list of potential tactical positions.

All knowledge generated by sensors is stored in working memory in a common format called a WorkingMemoryFact.

The decision-making mechanism is the primary difference between our architecture and C4, as we have replaced C4's "Action Tupples" with a real-time planner. When the sensors detect significant changes in the state of the world, the agent re-evaluates the relevance of his goals. Only one goal may be active at a time. When the most relevant goal changes, the agent uses the planner to search for the sequence of actions that will satisfy the goal. The planner validates action preconditions with WorkingMemoryFacts. An action activates by setting values on member variables of the blackboard. Subsystems update at some constant rate, and change their behavior according to instructions placed on the blackboard. For example, the GotoTarget action sets a new destination on the blackboard. The following update, the navigation system responds by finding a path to the new destination.

## Distributed Processing

While searching for a sequence of actions to satisfy a goal, the planner needs to validate each candidate action's preconditions. Some of these preconditions may be costly to compute, relying on ray intersection or pathfinding procedures. The planner needs to complete the entire search within one frame without interrupting the overall performance of the game, so it cannot afford to do costly computations on-demand. Instead, we use sensors to amortize the cost of these expensive computations over many frames, and cache results in working memory.

An NPC may have any number of sensors. Each sensor updates every frame if necessary, but many update less frequently or only in response to an event. Sensors perform ray intersection tests, pathfinding, and other expensive operations such as sorting or analyzing tactical positions. SensorSeeEnemy is an example of a sensor that remains dormant until some visual stimuli arrives, at which time the sensor performs a ray intersection test. SensorNodeCombat is a sensor that polls the world three times per second, searching for potential places to hide or fire from covered positions. This sensor collects a list of potentially valid nodes, and then sorts them based on their distance from the NPC. Validity is based on radii associated with the nodes that must contain the NPC's current target.

Initially, we only allowed NPCs to update one sensor per agent update. This kept the processing load as light as possible, but we discovered that this was too restrictive, resulting in noticeably delayed reactions. We found a better solution is to give the sensor's update routine a Boolean return value, and return true only if the sensor has performed a significant amount of work. It is up to the
programmer to determine what fits this criterion. Each frame, the NPC iterates over the sensors that do not need to update every frame, and continues to allow sensors to process until one returns true. All sensors that have an update rate of 0.0 update every frame, so these sensors generally perform lightweight operations.

In addition to evenly distributing the processing of multiple tasks, we also use sensors to incrementally process a single large task over many frames. When an NPC discovers a threat along the path to his current tactical destination, he crouches in place and re-evaluates possible destinations. Each frame, the PassTarget sensor finds the path to a known tactical position, and determines if the path is clear from danger. This process is repeated every frame until a safe route to a tactical position can be found. Distributed processing of sensors allows us to add intelligence to our NPCs that we could not previously support, due to the prohibitive cost of computing multiple paths per frame.

Constantly processing sensors certainly leads to more total processing than a system relying on lazy evaluation, but the overall load is more consistent and controlled. Sensors provide the planner with a constant stream of up-to-date data, eliminating the need for the planner to burden the CPU with processing beyond what is required by the search for a valid plan.

## Caching

Sensors cache perceptions in working memory, in the form of WorkingMemoryFacts. All types of knowledge are stored in this common format. A WorkingMemoryFact is a record containing a set of associated attributes. Different subsets of attributes are assigned depending on the type of knowledge the fact represents. We have ten possible types of knowledge, including Character, Object, Disturbance, Task, PathInfo, and Desire Facts.

A Fact record contains a total of 16 member attributes. The most commonly assigned attributes are the position, direction, stimulus type, object handle, and update time. Each attribute has an associated confidence value that ranges from 0.0 to 1.0 . Below is a pseudo-code representation of a WorkingMemoryFact:

```
WorkingMemoryFact
{
    Attribute<Vector3D> Position
    Attribute<Vector3D> Direction
    Attribute<StimulusType> Stimulus
    Attribute<Handle> Object
    Attribute<float> Desire
    float fUpdateTime
}
```

Where each Attribute looks like this:

```
Attribute<Type>
{
    Type Value
    float fConfidence
}
```


## Confidence Values

The meaning of the confidence value associated with each attribute varies widely, but is unified conceptually. Confidence may represent an NPC's current stimulation, proximity to some object, or degree of desire. When applied to the Stimulus attribute, confidence represents how confident the NPC is that he is sensing some stimulus. For example, the confidence of a Character Fact's Stimulus attribute indicates the current level of visual stimulation that the NPC is aware of for this character. The confidence associated with the Position attribute represents the NPC's confidence in this location as a destination. A sensor that searches for tactical positions uses the confidence value of the Position attribute to indicate how close the node is to the NPC. The sensor sorts the nodes by distance and normalizes the confidence values to fall between 0.0 and 1.0 . The node with the highest positional confidence is the closest. The intensity of an NPC's Desire attribute is characterized by his confidence that he is feeling this desire. The confidence value of a Desire Fact's Desire attribute indicates the NPC's current urge to satisfy some desire.

The planner can take advantage of the consistent knowledge representation and associated confidence values while validating preconditions. Working memory provides generic query functions to search for a matching Fact, a count of matching Facts, or a Fact with the maximum positional or stimulus confidence. Using this consistent interface, the planner can query working memory for the nearest tactical position, or the most visible enemy.

## Centralized Knowledge

Caching all knowledge in a consistent format does not directly improve the efficiency of the planner, but rather provides a means of a global optimization. Facts could be hashed into bins based on the type of knowledge, or sorted in some manner. At a minimum, the most recently or most frequently accessed Fact could be cached for immediate retrieval. We did not find linear searches through working memory to be a performance bottleneck, so we did not apply any optimizations. As the number of Facts scales, it may be worthwhile to pursue query optimization.

Centralizing knowledge in working memory or on the blackboard provides the NPC with a persistent context that is often lost in FSM or scripted systems, as the NPC
transitions between states or scripts. For instance, if the NPC eliminates a threat, he can immediately query working memory to determine who to target next. If the NPC stops climbing a ladder to fire at someone below, the knowledge that he was in the process of climbing a ladder persists on the blackboard. If knowledge is instead stored in member variables of states or scripts, information is often lost when an NPC's behavior changes.

## Garbage Collection

One notable issue that caching introduces is that of garbage collection. Over the course of the game, working memory fills up with Facts that may be no longer useful to the NPC. It is unclear who is responsible for cleaning out irrelevant facts. Some of our sensors take the C++ approach to garbage collection, where the creator is responsible for destroying the Facts that it deposited. For instance, SensorNodeCombat clears existing Facts about tactical positions from working memory before creating new ones. This scheme does not work as well for sensors like SensorHearDisturbance, which creates Facts for each disturbance detected, and waits for the planner to respond by sending the NPC to investigate, and then clear Disturbance Facts upon completion. We left it in the programmer's hands to clean up Facts in different ways on a case by case basis. A safer approach may be to assign an expiration time to all Facts, and collect garbage periodically. Subsystems could extend expiration times where necessary.

## Lightweight Planning

Outsourcing costly operations to sensors relieves the planner of much of the processing burden while searching. The planner's search operation itself is the last obstacle in reliably planning fast enough for real-time. We have taken a number of steps to minimize the search space, and optimize precondition validation.

We minimize the search space by placing strict limitations on the representation of action preconditions and effects. Preconditions and effects are represented symbolically, as a fixed sized array of key-value pairs. Appendix B contains a complete listing of our enumerated symbols, which are paired with four byte values. The value may be an integer, float, bool, handle, enum, or a reference to another symbol. The planner uses the precondition symbols to minimize the search space to only those actions that have effects matching the preconditions existing in the plan generated so far. In other words, the search only takes potentially fruitful branches rather than testing every combination of actions. Actions are stored in a hash table sorted by the effect symbols, so the planner can instantly find a list of candidates to satisfy some precondition. One action may be referenced by multiple hash table bins if it has multiple effects.

In addition to the symbolic preconditions, we further prune the search tree with "context preconditions." Actions may optionally provide a context precondition validation function of arbitrary code to prevent the action from further consideration. This validation function is where the planner queries values cached in working memory, or on the blackboard. For example, an NPC reacting to a disturbance checks his working memory to determine which disturbances he is aware of. If the NPC has detected a dangerous disturbance like an incoming grenade, he will consider the ReactToDanger or EscapeDanger actions, rather than the InspectDisturbance or LookAtDisturbance actions. All four of these actions have the symbolic effect of setting the DisturbanceExists symbol to false. An action may also have a context effect function, which runs arbitrary code after the action completes execution.

The planner represents its view of the current state of the world using the same array structure as that used to represent symbolic preconditions and effects. This makes it trivial to validate any precondition. We index the array by the enumerated symbols, so we can instantly determine if the planner believes that WeaponArmed is true, or AtNode equals "node66" in the current world state.

Storing the symbols in a fixed sized array of key-value pairs does restrict preconditions and world state representation in several ways. First, we have no means of describing who a symbol refers to. Next, preconditions are limited to a conjunction of clauses. Each symbol may only be used in one clause of an action's complete precondition expression. Finally, the total number of unique symbols needs to be managed, to minimize memory consumption since each node of the search tree contains a copy of the state of the world determined so far.

"""

from __future__ import absolute_import
from __future__ import unicode_literals


class OperationFailedError(Exception):
    def __init__(self, reason):
        self.msg = reason


class SensorError(Exception):
    """Sensor's Error base class"""


class SensorMultipleTypeError(SensorError):
    """Sensor can not be two type at once"""


class SensorDoesNotExistError(SensorError):
    """Sensor do not exist"""


class SensorAlreadyInCollectionError(SensorError):
    """Sensor do not exist"""


class PlanError(Exception):
    """Generic plan error"""


class PlanFailed(PlanError):
    """Failed to produce a plan"""


class ActionError(Exception):
    """Action's Error base class"""


class ActionMultipleTypeError(ActionError):
    """Action cannot be two types at once"""


class ActionAlreadyInCollectionError(ActionError):
    """Action with same name already in collection"""


from typing import Callable, List, Optional


class Action:
    """The Action class defines the interface used by the planner
        to convert the actions into graph node's edges
    func: Callable, a function or callable object
    name: Action name used as ID
    conditions: the world state condition required for
                this action to be executed
    effect: what is the expected world state after the action execution
    """

    def __init__(
        self,
        func: Callable,
        name: str,
        conditions: dict,
        effects: dict,
        cost: float = 0.1,
    ):
        self.func = func
        self.name = name
        self.conditions = conditions
        self.effects = effects
        self.cost = cost
        self._response: Optional[ActionResponse] = None

    def __str__(self):
        return self.name

    def __repr__(self):
        return self.__str__()

    def __cmp__(self, other):
        if len(self.__dict__) < len(other.__dict__):
            return -1
        elif len(self.__dict__) > len(other.__dict__):
            return 1
        else:
            return 0

    def __hash__(self):
        return hash(self)

    def __call__(self):
        return self.exec()

    @property
    def response(self):
        return self._response

    @response.setter
    def response(self, response):
        self._response = response

    def exec(self):
        try:
            stdout, stderr, return_code = self.func()
        except RuntimeError as e:
            raise RuntimeError(f"Error executing function {self.func}. Exception: {e}")
        self.response = ActionResponse(
            stdout=stdout, stderr=stderr, return_code=return_code
        )
        return self.response


class ActionResponse:
    def __init__(
        self,
        stdout: str = "",
        stderr: str = "",
        return_code: int = 0,
        trim_chars: str = "\r\n",
    ):
        """

        :param return_code:
        :param stdout:
        :param stderr:
        """
        self.stdout = stdout
        self.stderr = stderr
        self.return_code = return_code
        self.trim_chars = trim_chars
        self.response = None

    def __call__(self):
        return self.response

    def __str__(self):
        return f"{self.response}"

    def __repr__(self):
        return self.__str__()

    @staticmethod
    def __trim(string: str):
        return string.strip("\r\n")

    @property
    def stdout(self):
        return self._stdout

    @stdout.setter
    def stdout(self, value: str):
        self._stdout = self.__trim(value)

    @property
    def stderr(self):
        return self._stderr

    @stderr.setter
    def stderr(self, value: str):
        self._stderr = self.__trim(value)

    @property
    def return_code(self):
        return self._return_code

    @return_code.setter
    def return_code(self, value: int):
        self._return_code = value

    @property
    def response(self):
        if self.stdout:
            return self.stdout
        elif self.stderr:
            return self.stderr

    @response.setter
    def response(self, value):
        self._response = value


class Actions:

    def __init__(self, actions: List[Action] = None):
        self.actions = actions if actions else []

    def __str__(self):
        names = [action.name for action in self.actions]
        return "{}".format(names)

    def __repr__(self):
        return self.__str__()

    def __iter__(self):
        return iter(self.actions)

    def __len__(self):
        if self.actions:
            return len(self.actions)
        else:
            return 0

    def __getitem__(self, key: str) -> Optional[Action]:
        for action in self.actions:
            if action.name == key:
                return action
            else:
                return None

    def get(self, name: str) -> Optional[Action]:
        result = None
        if not self.actions:
            return result

        for action in self.actions:
            if action.name == name:
                result = action

        return result

    def get_by_conditions(self, conditions: dict) -> Optional[List[Action]]:
        result = []
        for action in self.actions:
            if action.conditions == conditions:
                result.append(action)
        return result

    def get_by_effects(self, effects: dict) -> Optional[List[Action]]:
        result = []
        for action in self.actions:
            if action.effects == effects:
                result.append(action)
        return result

    def add(
        self,
        name: str,
        conditions: dict,
        effects: dict,
        func: Callable,
        cost: float = 0.1,
    ):
        if self.get(name):
            raise ActionAlreadyInCollectionError(
                f"The action name {name} is already in use"
            )
        self.actions.append(Action(func, name, conditions, effects, cost))

    def remove(self, name: str):
        result = False
        if not self.actions:
            return result
        action = self.get(name)
        if action:
            self.actions.remove(action)
            result = True
        return result

    def run_all(self) -> list:
        responses = [action.exec() for action in self.actions]
        return responses

    @staticmethod
    def compare_actions(action1: Action, action2: Action) -> bool:
        result = False
        if (
            action1.conditions == action2.conditions
            and action1.effects == action2.effects
        ):
            result = True

        return result


import networkx as nx


class Node(object):

    def __init__(self, attributes: dict, weight: float = 0.0):
        self.attributes = attributes
        self.weight = weight
        self.name = str(self.attributes)

    def __str__(self):
        return self.name

    def __repr__(self):
        return self.__str__()


class Edge(object):

    def __init__(
        self,
        name,
        predecessor: Node,
        successor: Node,
        cost: float = 0.0,
        obj: object = None,
    ):
        self.name = name
        self.cost = cost
        self.predecessor = predecessor
        self.successor = successor
        self.obj = obj

    def __str__(self) -> str:
        return self.name

    def __repr__(self) -> str:
        return self.__str__()


class Nodes(object):

    def __init__(self):
        self.nodes = []

    def __add__(self, other: Node):
        self.nodes.append(other)

    def __iter__(self):
        return iter(self.nodes)

    def add(self, other: Node):
        if other not in self.nodes:
            self.__add__(other)

    def get(self, attr):
        result = None
        for node in self.nodes:
            if node.attributes == attr:
                result = node
        return result


class Edges(object):

    def __init__(self, edges: list = None):
        if edges:
            for edge in edges:
                self.add(edge)
        else:
            self.edges = []

    def __add__(self, other: Edge):
        self.edges.append(other)

    def __iter__(self):
        return iter(self.edges)

    def add(self, other: Edge):
        self.__add__(other)


class Graph(object):
    def __init__(self, nodes: Nodes, edges: Edges):
        self.directed = nx.DiGraph()
        self.add_nodes_from(nodes=nodes)
        self.add_edges_from(edges=edges)
        self.__size = self.size

    def __repr__(self):
        return self.directed

    @staticmethod
    def __is_dst(src: dict, dst: dict) -> bool:
        if src == dst:
            return True
        else:
            return False

    @property
    def size(self):
        return len(self.directed.nodes)

    def __add_node(self, node: Node, attribute: dict):
        self.directed.add_node(node, attr_dict=attribute, label=node.name, object=node)

    def __add_edge(self, edge: Edge):
        self.directed.add_edge(
            edge.predecessor,
            edge.successor,
            object=edge.obj,
            weight=edge.cost,
            label=edge.name,
        )

    def add_nodes_from(self, nodes: Nodes):
        [self.__add_node(node, attribute=node.attributes) for node in nodes]

    def add_edges_from(self, edges: Edges):
        [self.__add_edge(edge=edge) for edge in edges]

    def edge_between_nodes(self, path: list, data: bool = True):
        return self.directed.edges(path, data=data)

    def nodes(self, data: bool = True):
        return self.directed.nodes(data=data)

    def edges(self, data: bool = True):
        return self.directed.edges(data=data)

    def search_node(self, attr: dict = None):
        result = None
        if attr:
            for node in self.directed.nodes(data=True):
                if node[1]["attr_dict"].items() == attr.items():
                    result = node[0]
        return result

    def path(self, src: dict, dst: dict):
        if not self.__is_dst(src, dst):
            return nx.astar_path(self.directed, src, dst, weight="weight")

    def plot(self, file_path: str):
        try:
            import matplotlib.pyplot as plt
        except ImportError as err:
            raise ImportError(f"matplotlib not installed. Failed at: {err}")

        try:
            pos = nx.nx_agraph.graphviz_layout(self.directed)
            nx.draw(
                self.directed,
                pos=pos,
                node_size=1200,
                node_color="lightblue",
                linewidths=0.25,
                font_size=8,
                font_weight="bold",
                with_labels=True,
                dpi=5000,
            )
            # edge_labels = nx.get_edge_attributes(self.directed, name='attr_dict')
            # nx.draw_networkx_edge_labels(self.directed, pos=pos, edge_labels=edge_labels)
            plt.savefig(file_path)
        except IOError as err:
            raise IOError(f"Could not create plot image: {err}")


class Planner(object):

    def __init__(self, actions: Actions):
        """
        :param actions: list of actions
        """
        # init vars
        self.goal = None
        self.world_state = None
        self.actions = actions
        self.states = Nodes()
        self.transitions = Edges()
        self.action_plan = []
        self.graph = Graph(nodes=self.states, edges=self.transitions)

    def __generate_states(self, actions: Actions, world_state: dict, goal: dict):
        self.states.add(Node(world_state))
        self.states.add(Node(goal))
        for action in actions:
            pre = {**world_state, **action.conditions}
            eff = {**pre, **action.effects}
            self.states.add(Node(attributes=pre))
            self.states.add(Node(attributes=eff))

    def __generate_transitions(self, actions, states):
        for action in actions:
            for state in states:
                if action.conditions.items() <= state.attributes.items():
                    attr = {**state.attributes, **action.effects}
                    suc = self.states.get(attr)
                    self.transitions.add(
                        Edge(
                            name=action.name,
                            predecessor=state,
                            successor=suc,
                            cost=action.cost,
                            obj=action,
                        )
                    )

    def plan(self, state: dict, goal: dict) -> list:
        self.world_state = state
        self.goal = goal
        self.__generate_states(self.actions, self.world_state, self.goal)
        self.__generate_transitions(self.actions, self.states)
        self.graph = Graph(self.states, self.transitions)
        world_state_node = self.states.get(state)
        goal_node = self.states.get(goal)
        plan = []
        if state != goal:
            try:
                path = self.graph.path(world_state_node, goal_node)
            except EnvironmentError as e:
                print(f"No possible path: {e}")

            try:
                plan = self.graph.edge_between_nodes(path)
            except EnvironmentError as e:
                print(f"No plan available: {e}")

        return plan


from typing import Callable, List


class Sensor:
    """Sensor object factory"""

    def __init__(self, name: str, binding: str, func: Callable):
        """Sensor object model

        :param binding: string containing the key name
                        which the sensor will right to
        :param name: string containing the name of the sensor
        """
        self.binding = binding
        self.name = name
        self.func = func
        self.response = {}

    def __str__(self):
        return self.name

    def __repr__(self):
        return self.__repr__()

    def __call__(self):
        return self.exec()

    def exec(self):
        try:
            stdout, stderr, return_code = self.func()
        except RuntimeError as e:
            raise RuntimeError(f"Error executing function {self.func}. Exception: {e}")
        self.response = SensorResponse(
            stdout=stdout, stderr=stderr, return_code=return_code
        )
        return self.response


class SensorResponse:

    def __init__(
        self,
        stdout: str = "",
        stderr: str = "",
        return_code: int = 0,
    ):
        """

        :param name:
        :param sensor_type:
        """
        self._stdout = stdout
        self._stderr = stderr
        self.return_code = return_code

    def __str__(self):
        response = self.stdout
        if self.stderr:
            response = self.stderr
        return "Response: {}, ReturnCode: {}".format(response, self.return_code)

    def __repr__(self):
        return self.__str__()

    @property
    def stdout(self):
        return self._stdout

    @stdout.setter
    def stdout(self, value: str):
        self._stdout = value.rstrip("\r\n")

    @property
    def stderr(self):
        return self._stderr

    @stderr.setter
    def stderr(self, value: str):
        self._stderr = value.rstrip("\r\n")

    @property
    def response(self):
        if self.stdout:
            return self.stdout
        else:
            return self.stderr

    @response.setter
    def response(self, value):
        self.response = value


class Sensors:

    def __init__(self, sensors: List[Sensor] = None):
        """Collection of sensors, adds only unique sensors

        :param sensors: List containing the sensor objects
        """
        self.sensors = sensors if sensors else []

    def __str__(self):
        names = [sensor.name for sensor in self.sensors]
        return "{}".format(names)

    def __repr__(self):
        return self.__str__()

    def __len__(self):
        if self.sensors:
            return len(self.sensors)
        else:
            return 0

    def __iter__(self):
        return iter(self.sensors)

    def __delete__(self, sensor):
        if sensor in self.sensors:
            self.sensors.remove(sensor)
        else:
            raise SensorDoesNotExistError

    def __call__(self, name: str):
        """Search for sensor, return None if does not match

        :param name: sensor's name
        :return: Sensor
        """
        sens = None
        for s in self.sensors:
            if s.name == name:
                sens = s
        return sens

    def get(self, name):
        result = None
        if not self.sensors:
            return result

        for sensor in self.sensors:
            if sensor.name == name:
                result = sensor

        return result

    def add(self, name: str, binding: str, func: Callable):
        if not self.get(name=name):
            self.sensors.append(Sensor(name=name, binding=binding, func=func))
        else:
            raise SensorAlreadyInCollectionError(
                f"Another sensor is using the same name: {name}"
            )

    def remove(self, name: str):
        result = False
        if not self.sensors:
            return result
        sensor = self.get(name)
        if sensor:
            self.sensors.remove(sensor)
            result = True
        return result

    def run_all(self) -> list:
        responses = [sensor.exec() for sensor in self.sensors]
        return responses


class WorldState(dict):
    """
    ws = WorldState({'first_name': 'Eduardo'}, last_name='Pool', age=24, sports=['Soccer'])
    """

    def __init__(self, *args, **kwargs):
        super(WorldState, self).__init__(*args, **kwargs)
        for arg in args:
            if isinstance(arg, dict):
                for k, v in arg.items():
                    self[k] = v

        if kwargs:
            for k, v in kwargs.items():
                self[k] = v

    def __getattr__(self, attr):
        return self.get(attr)

    def __setattr__(self, key, value):
        self.__setitem__(key, value)

    def __setitem__(self, key, value):
        super(WorldState, self).__setitem__(key, value)
        self.__dict__.update({key: value})

    def __delattr__(self, item):
        self.__delitem__(item)

    def __delitem__(self, key):
        super(WorldState, self).__delitem__(key)
        del self.__dict__[key]

    def __le__(self, other):
        for k, v in other.__dict__():
            if other.__dict__()[k] != v:
                return False
        return True

    def __eq__(self, other):
        if other.items() != self.items():
            return False
        else:
            return True

    def __hash__(self):
        return hash(tuple(sorted(self.items())))


from time import sleep
from datetime import datetime
from automat import MethodicalMachine


class Fact(object):
    def __init__(self, sensor, data, binding):
        self.binding = binding
        self.data = data
        self.time_stamp = datetime.now()
        self.parent_sensor = sensor

    def __str__(self):
        return "{}: {}".format(self.binding, self.data)

    def __repr__(self):
        return self.__str__()


class AutomatonPriorities:
    def __init__(self, items: list):
        self._items = items

    def __iter__(self):
        return self._items

    def __repr__(self):
        return str(self.__dict__)

    def __str__(self):
        return self.__repr__()


class Automaton:
    """A 3 State Machine Automaton: observing (aka monitor or patrol), planning and acting"""

    machine = MethodicalMachine()

    def __init__(
        self, name: str, sensors: Sensors, actions: Actions, world_state_facts: dict
    ):
        # setup
        self.world_state = WorldState(world_state_facts)
        self.working_memory = []
        self.name = name
        self.sensors = sensors
        self.actions = actions
        self.planner = Planner(actions=actions)
        #
        self.action_plan = []
        self.action_plan_response = None
        self.sensors_responses = {}
        self.actions_response = []
        self.goal = {}

    def __sense_environment(self):
        for sensor in self.sensors:
            self.working_memory.append(
                Fact(sensor=sensor.name, data=sensor.exec(), binding=sensor.binding)
            )
        for fact in self.working_memory:
            setattr(self.world_state, fact.binding, fact.data.response)

    def __set_action_plan(self):
        self.action_plan = self.planner.plan(self.world_state, self.goal)
        return self.action_plan

    def __execute_action_plan(self):
        self.actions_response = [
            action[2]["object"].exec() for action in self.action_plan
        ]
        return "Action planning execution results: {}".format(self.action_plan_response)

    @machine.state(initial=True)
    def waiting_orders(self):
        """Waiting goal / orders"""

    @machine.state()
    def sensing(self):
        """Running sensors and assimilating sensor's responses"""

    @machine.state()
    def planning(self):
        """Generating action plan to change actual world state to achieve goal"""

    @machine.state()
    def acting(self):
        """Executing action plan"""

    @machine.input()
    def wait(self):
        """Input waiting_orders state"""

    @machine.input()
    def sense(self):
        """Input sense state"""

    @machine.output()
    def __sense(self):
        """Execute sensors"""
        self.__sense_environment()

    @machine.input()
    def plan(self):
        """Input for planning state"""

    @machine.output()
    def __plan(self):
        """Generate action plan"""
        self.__set_action_plan()

    @machine.input()
    def act(self):
        """Input for acting state"""

    @machine.output()
    def __act(self):
        """Execute action plan"""
        self.__execute_action_plan()

    @machine.input()
    def input_goal(self, goal):
        """Change / Set AI goal"""

    @machine.output()
    def __input_goal(self, goal):
        """Actually sets goal"""
        self.goal = goal

    @machine.output()
    def __reset_working_memory(self):
        self.working_memory = []

    # cyclical main states
    waiting_orders.upon(sense, enter=sensing, outputs=[__sense])
    sensing.upon(plan, enter=planning, outputs=[__plan])
    planning.upon(act, enter=acting, outputs=[__act])
    acting.upon(sense, enter=sensing, outputs=[__reset_working_memory, __sense])
    # change orders
    waiting_orders.upon(input_goal, enter=waiting_orders, outputs=[__input_goal])
    planning.upon(input_goal, enter=waiting_orders, outputs=[__input_goal])
    acting.upon(input_goal, enter=waiting_orders, outputs=[__input_goal])
    # reset working memory from sensing
    sensing.upon(wait, enter=waiting_orders, outputs=[__reset_working_memory])


class AutomatonController(object):

    def __init__(
        self, actions: Actions, sensors: Sensors, name: str, world_state: dict
    ):
        self.automaton = Automaton(
            actions=actions, sensors=sensors, name=name, world_state_facts=world_state
        )

    @property
    def world_state(self):
        return self.automaton.world_state

    @world_state.setter
    def world_state(self, value):
        self.automaton.world_state = value

    @property
    def goal(self):
        return self.automaton.goal

    @goal.setter
    def goal(self, value):
        self.automaton.input_goal(value)

    def start(self):
        while True:
            self.automaton.sense()
            if self.automaton.world_state != self.goal:
                print(
                    "World state differs from goal: \nState: {}\nGoal: {}".format(
                        self.automaton.world_state, self.goal
                    )
                )
                print("Need to find an action plan")
                self.automaton.plan()
                print(
                    "Plain found. Will execute the action plan: {}".format(
                        self.automaton.action_plan
                    )
                )
                self.automaton.act()
            else:
                print("World state equals to goal: {}".format(self.goal))
                self.automaton.wait()
            sleep(5)


from typing import Optional, Tuple
from subprocess import Popen, PIPE


class ShellCommand(object):
    """Creates an callable object which executes a shell command"""

    def __init__(self, command: str, timeout: int = 30):
        self.command = command
        self.timeout = timeout
        self.response = None

    def __call__(self):
        return self.run(self.command)

    def run(self, command=Optional[str]) -> Tuple[str, str, int]:
        process = Popen(
            ["/bin/sh", "-c", command],
            shell=False,
            stdout=PIPE,
            stderr=PIPE,
            universal_newlines=True,
        )
        try:
            stdout, stderr = process.communicate(timeout=self.timeout)
            return_code = process.returncode
            self.response = (stdout, stderr, return_code)
        except RuntimeError as e:
            raise Exception(f"Error opening process {self.command}: {e}")
        finally:
            process.kill()

        return self.response


def setup_sensors():
    sense_dir_state = ShellCommand(
        command='if [ -d "/tmp/goap_tmp" ]; then echo -n "exist"; else echo -n "not_exist"; fi'
    )
    sense_dir_content = ShellCommand(
        command='[ -f /tmp/goap_tmp/.token ] && echo -n "token_found" || echo -n "token_not_found"'
    )
    sensors = Sensors()
    sensors.add(name="SenseTmpDirState", func=sense_dir_state, binding="tmp_dir_state")
    sensors.add(
        name="SenseTmpDirContent", func=sense_dir_content, binding="tmp_dir_content"
    )
    return sensors


def setup_actions():
    mkdir = ShellCommand(command="mkdir -p /tmp/goap_tmp")
    mktoken = ShellCommand(command="touch /tmp/goap_tmp/.token")
    actions = Actions()
    actions.add(
        name="CreateTmpDir",
        conditions={"tmp_dir_state": "not_exist", "tmp_dir_content": "token_not_found"},
        effects={"tmp_dir_state": "exist", "tmp_dir_content": "token_not_found"},
        func=mkdir,
    )
    actions.add(
        name="CreateToken",
        conditions={"tmp_dir_state": "exist", "tmp_dir_content": "token_not_found"},
        effects={"tmp_dir_state": "exist", "tmp_dir_content": "token_found"},
        func=mktoken,
    )
    return actions


def setup_automaton():
    world_state_matrix = {
        "tmp_dir_state": "Unknown",
        "tmp_dir_content": "Unknown",
    }
    automaton = AutomatonController(
        name="directory_watcher",
        actions=setup_actions(),
        sensors=setup_sensors(),
        world_state=world_state_matrix,
    )
    return automaton


def main():
    goal = {
        "tmp_dir_state": "exist",
        "tmp_dir_content": "token_found",
    }
    dir_handler = setup_automaton()
    dir_handler.goal = goal
    dir_handler.start()


if __name__ == "__main__":
    main()

```

Reminder:
Your goal is to convert the code into a specification that would prompt someone to implement the *exact* system.
It is part of a homework assignment for students in a game programming course.

The quality of your specification will be evaluated by how well it can be used to implement the *exact* system, meaning that if you omit any details, the implementation will not be able to replicate the original system.
