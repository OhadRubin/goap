SPECIFICATION FOR A REGRESSIVE GOAP SYSTEM WITH REFERENCES

INTRODUCTION

Your task is to implement a regressive Goal-Oriented Action Planning (GOAP) system in Python that exactly matches the features and behaviors described below. The system must support references—i.e., dynamic data passed from one action’s effect into another action’s precondition—and perform A* search backward from the goal state. Furthermore, your implementation must allow the planner to invalidate and replan when world conditions change. Follow every detail in these requirements to ensure your implementation can replicate the original system exactly.

TABLE OF CONTENTS  
1. Terminology and High-Level Structure  
2. Required Data Structures and Types  
3. Priority Queue Implementation  
4. A* Algorithm (AStarAlgorithm) Requirements  
5. The Action System  
    5.1 ActionValidator (metaclass)  
    5.2 Action Class Requirements  
    5.3 EffectReference and reference(...)  
6. RegressiveGOAPAStarNode Requirements  
7. RegressiveGOAPAStarSearch Requirements  
8. RegressivePlanner Requirements  
9. Visualizing the Plan (Optional Utility)  
10. Example Usage and Expected Behavior  



1. TERMINOLOGY AND HIGH-LEVEL STRUCTURE
A) TERMINOLOGY  
• “Goal State”: A dictionary describing the desired conditions (e.g., {"is_in_cover": True}).  
• “World State”: A dictionary describing the current conditions (e.g., {"has_table": True, "is_undead": False}).  
• “Action”: A class that encodes (1) preconditions, (2) effects, and (3) cost.  
• “Regressive Planner”: A system that starts from a goal and works backward, finding which actions can satisfy that goal, and chaining those action dependencies until it reaches the known world state.  
• “Reference (EffectReference)”: A token that says “the actual value is an effect from a previous action.”  

B) CODE FLOW  
• The system uses an A* algorithm to search from the goal state backward to the initial state.  
• Each action has a preconditions dict and an effects dict. Effects may contain a literal or Ellipsis (...).  
• If an action states an effect "something": Ellipsis, it means “this effect is a service to be dynamically filled at runtime or by a referencing requirement from somewhere else.”  



2. REQUIRED DATA STRUCTURES AND TYPES
A) State Type  
Define a type alias for the world or goal state. It must be a dictionary mapping string keys to arbitrary Python data, for instance:
    
    State = Dict[str, Any]
B) PlanStep  
You must define a dataclass named PlanStep:
    
    @dataclass(frozen=True)
    class PlanStep:
        action: Action
        services: State

Where:  
• action is an instance of Action used in that step of the plan.  
• services is a dictionary containing resolved references or runtime data needed by this action.  



3. PRIORITY QUEUE IMPLEMENTATION
A) PriorityElement  
Create a class PriorityElement to store items and their priority scores:
    
    class PriorityElement:
        def __init__(self, element, score):
            self.value = element
            self.score = score
            self.removed = False

        def __lt__(self, other):
            return self.score < other.score

B) PriorityQueue  
Implement a PriorityQueue that uses a binary heap internally.  
• Must internally track items by storing PriorityElement objects in a min-heap using heapq.  
• The queue must have methods add(item), pop(), remove(item), and must handle “logical removal” of items by marking them as “removed” but only physically removing them when popped from the heap:
    class PriorityQueue:
        def __init__(self, items=None, key=None):        
        def add(self, item):        
        def pop(self):        
        def remove(self, item):
Ensure item uniqueness is enforced. The optional key parameter dictates the priority score.



4. A* ALGORITHM (AStarAlgorithm) REQUIREMENTS
Create an abstract base class AStarAlgorithm (from abc.ABC) that dictates the search structure:
    class AStarAlgorithm(ABC):
        @abstractmethod
        def get_neighbours(self, node):
            pass
        @abstractmethod
        def get_g_score(self, current, node):
            pass
        @abstractmethod
        def get_h_score(self, node):
            pass
        def find_path(self, start, end):
        @abstractmethod
        def is_finished(self, node, goal, parents):
            pass

        def reconstruct_path(self, node, goal, parents):
Key points:  
• find_path(start, end) implements the main A* loop.  
• is_finished(node, goal, parents) checks whether the search is done.  
• reconstruct_path(...) uses parent pointers to trace the path once found.



5. THE ACTION SYSTEM
5.1 ActionValidator (metaclass)

You must define a metaclass named ActionValidator that, upon class creation, will:  
1) Check that preconditions do not store Ellipsis (...).  
2) Build a list of “service_names” from effects fields whose values are Ellipsis.  
3) Check that references in preconditions refer to valid effect keys if referencing an effect.

    class ActionValidator(type):
        def __new__(mcs, cls_name, bases, attrs):            attrs["service_names"] = [...]
            # Validate no preconditions == Ellipsis
            # etc.
            return super().__new__(mcs, cls_name, bases, attrs)

5.2 Action Class Requirements

Create a class Action that uses ActionValidator as its metaclass:

    class Action(metaclass=ActionValidator):
        effects: ClassVar[State] = {}
        preconditions: ClassVar[State] = {}
        service_names: ClassVar[List[str]] = []
        
        cost = 1.0
        precedence = 0.0
        apply_effects_on_exit = True

        def check_procedural_precondition(self, services: State, is_planning: bool) -> bool:
            return True
        
        def get_cost(self, services) -> float:
            return self.cost

Explanation:  
• effects is a dict of key->value describing changes in the world upon completion. If the value is Ellipsis, that becomes a “service.”  
• preconditions is a dict of key->value describing requirements to run. The value can be a literal (e.g. True) or a reference (EffectReference).  
• cost is a numeric cost for A*; higher means more expensive actions.  
• precedence is used to sort possible actions if needed (the system sorts by descending precedence).  
• check_procedural_precondition(...) is an optional hook to allow code-based checks. Return False if the action is not valid.  
• get_cost(...) returns the numeric cost for the action, by default self.cost.

5.3 EffectReference and reference(...)

Implement a class EffectReference representing a dynamic reference:

    class EffectReference:
        def __init__(self, name):
            self.goap_effect_reference = name

Implement a helper function reference(name: str) -> EffectReference that simply constructs an EffectReference:

    def reference(name: str) -> EffectReference:
        return EffectReference(name)

Any precondition key that uses reference("some_effect_name") is telling the planner: “I rely on an effect named 'some_effect_name' from a prior action’s effect dictionary.”


6. REGRESSIVEGOAPASTARNODE REQUIREMENTS

Define a dataclass (or regular class) RegressiveGOAPAStarNode with:  
• current_state: State  
• goal_state: State  
• action: Optional[Action] = None  

When hashing or comparing nodes, you should be able to store them in sets or dictionaries. For instance:

    @dataclass(frozen=True)
    class RegressiveGOAPAStarNode:
        current_state: State
        goal_state: State
        action: Optional[Action] = None

    def __hash__(self):
        # must use id(self) or other suitable way
        return id(self)

Provide these properties and methods:

• services property  
  Returns a dictionary with entries for the action’s service_names read from current_state.  

• is_satisfied property  
  Determines if the node’s goal_state is fully satisfied by current_state.  

• unsatisfied_keys property  
  Returns a list of all keys in goal_state that are not satisfied in current_state.  

• compute_cost(self, other: "RegressiveGOAPAStarNode") -> float  
  Returns the cost of transitioning from this node to the other node, typically other.action.get_cost(other.services).  

• apply_action(self, world_state: State, action: Action) -> RegressiveGOAPAStarNode  
  Creates a new RegressiveGOAPAStarNode by applying action’s effects. In a regressive approach, this means we modify the node’s goal_state to reflect the preconditions and adopt or unify certain states, including handling references. This is the core of the backward-search logic.



7. REGRESSIVEGOAPASTARSEARCH REQUIREMENTS

Extend AStarAlgorithm to search in a regressive manner:

    class RegressiveGOAPAStarSearch(AStarAlgorithm):
        def __init__(self, world_state: State, actions: List[Action]):        
        def get_neighbours(self, node: RegressiveGOAPAStarNode):        
        def get_h_score(self, node: RegressiveGOAPAStarNode):        
        def get_g_score(self, node: RegressiveGOAPAStarNode, neighbour: RegressiveGOAPAStarNode):        
        def is_finished(self, node: RegressiveGOAPAStarNode, goal, parents):        
        def reconstruct_path(self, node, goal, parents):
Key details in get_neighbours(node):  
• For each unsatisfied key in node.goal_state, find all actions whose effects satisfy that key or contain Ellipsis for that key.  
• Create a new neighbor node by calling node.apply_action(...) with that action.  
• If action.check_procedural_precondition(...) fails, skip that neighbour.  
• Sort neighbours by descending action.precedence (highest first).
Use get_h_score(...) to return the count of unsatisfied keys or any suitable heuristic.  
Use get_g_score(...) to return node.compute_cost(neighbour).



8. REGRESSIVEPLANNER REQUIREMENTS
Define RegressivePlanner:
    class RegressivePlanner:
        def __init__(self, world_state: State, actions: List[Action]):
            self._actions = actions
            self._world_state = world_state
            self._search = RegressiveGOAPAStarSearch(world_state, actions)

        def find_plan(self, goal_state: State) -> List[PlanStep]:
            # 1) Construct an initial node from the subset of the world_state relevant to goal_state
            # 2) Use self._search.find_path(...)
            # 3) Convert the resulting path of nodes into a forward-ordered plan of PlanStep
        # (Optional) Additional methods or properties
Steps:  
1) Build an initial RegressiveGOAPAStarNode containing:  
   – current_state with keys from goal_state, mapped from the actual world_state.  
   – goal_state matching the user’s requested goal.  
2) Call self._search.find_path(...) to get a path.  
3) Reconstruct that path in forward order, ignoring the first node’s action=None, and building a List[PlanStep].  



9. VISUALIZING THE PLAN (OPTIONAL UTILITY)
Optionally, define a function visualise_plan(plan, filename) that uses networkx and matplotlib to draw the plan steps as nodes with edges in order:
    def visualise_plan(plan, filename):
        graph = DiGraph()
        ...
        plt.savefig(filename)
        plt.close()
necessary for the core planner, but if you do include it, replicate the approach of:  
1) Creating a DiGraph.  
2) Adding each plan step as a node.  
3) Adding edges from step to next step.  
4) Drawing with networkx, saving to an image file.


10. EXAMPLE USAGE AND EXPECTED BEHAVIOR
Below is a minimal example demonstrating how your final system should be used:

Example 1: Flipping tables and taking cover (simple demonstration)
------------------------------------------------------------------

    # 1) Define your actions
    class FlipTable(Action):
        effects = {
            "table_id": ...  # Provides a table ID
        }
        preconditions = {
            "has_table": True
        }
    
    class TakeCoverBehindTable(Action):
        effects = {
            "is_in_cover": True
        }
        preconditions = {
            "table_to_hide_behind": reference("table_id")
        }

    # 2) Define your initial world_state and goal_state
    world_state = {
        "has_table": True,
        ...
    }
    goal_state = {
        "is_in_cover": True
    }

    # 3) Run the planner
    actions = [FlipTable(), TakeCoverBehindTable()]
    planner = RegressivePlanner(world_state, actions)
    plan = planner.find_plan(goal_state)

    # 4) Evaluate the plan steps
    for step in plan:
        print(step)

You should see steps that indicate that the “FlipTable” must occur (yielding table_id) before “TakeCoverBehindTable” can be satisfied.

Example 2: Handoff of references  
--------------------------------
(Provided in the original code snippet, see “HauntWithMagic,” “PerformMagic,” etc.)

    class HauntWithMagic(Action):
        effects = {"is_spooky": True}
        preconditions = {"is_undead": True, "performs_magic": "abracadabra"}

    class BecomeUndead(Action):
        effects = {"is_undead": True}
        preconditions = {"is_undead": False}

    class PerformMagic(Action):
        effects = {"performs_magic": ...}
        preconditions = {
            "chant_incantation": reference("performs_magic"),
            "cast_spell": reference("performs_magic")
        }

    class ChantIncantation(Action):
        effects = {"chant_incantation": ...}
        preconditions = {}

    class CastSpell(Action):
        effects = {"cast_spell": ...}
        preconditions = {}

    world_state = {"is_spooky": False, "is_undead": False}
    goal_state = {"is_spooky": True}
    actions = [HauntWithMagic(), BecomeUndead(), PerformMagic(), ChantIncantation(), CastSpell()]
    planner = RegressivePlanner(world_state, actions)
    plan = planner.find_plan(goal_state)
    for step in plan:
        print(step)

EXPECTED OUTPUT:  
The system automatically inserts “ChantIncantation” and “CastSpell” to produce the required references for “PerformMagic,” which in turn satisfies “performs_magic” = “abracadabra” for “HauntWithMagic.” The plan must also satisfy “BecomeUndead” because “HauntWithMagic” requires “is_undead = True.”


IMPLEMENTATION CHECKLIST

When your work is complete, you must be able to:

• Construct a RegressivePlanner with a dictionary representing the current world state and a list of available Action objects.  
• Provide a goal_state dictionary.  
• Call find_plan(goal_state) to return a list of PlanStep objects representing an action sequence leading from the current state to the goal state.  
• Each PlanStep must include references (services) resolved appropriately from “...”, reference(...), or direct effect values.  
• The code must correctly handle multiple references, references referencing different effect keys, and repeated usage of the same action class with different references.  

By following the above specification, your system will replicate the original regressive GOAP system with references in full fidelity. Make sure not to omit or alter any of the key details described. Good luck!